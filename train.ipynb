{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNjSbHTsWApfJDFHG0QmWx0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyRYVJ2sBdCb","executionInfo":{"status":"ok","timestamp":1697688170775,"user_tz":-330,"elapsed":32713,"user":{"displayName":"Made Saral","userId":"07554071970660769363"}},"outputId":"e4e02023-8d35-40bd-812c-e2bbc9e6adae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":[],"metadata":{"id":"1VAHZUoH86bC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('/content/gdrive/MyDrive/trained_model.h5')\n","\n","print(\"Model saved successfully.\")"],"metadata":{"id":"wnlI0DwHD6bU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nkGorxG-8lKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_jZ7XP-c8lN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#new resnet"],"metadata":{"id":"-u3_s5hzRdGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define the paths\n","train_dir = '/content/gdrive/MyDrive/archive (3)/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n","valid_dir = '/content/gdrive/MyDrive/archive (3)/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n","\n","# Define image size and batch size\n","img_size = (224, 224)\n","batch_size = 32\n","\n","# Create data generators with data augmentation for training images\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","valid_generator = valid_datagen.flow_from_directory(\n","    valid_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Load pre-trained ResNet50 model without top (fully connected) layers\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Add custom top layers for your specific classification task\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(17, activation='softmax')  # 17 classes for crop diseases\n","])\n","\n","# Compile the model\n","model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=1,\n","    validation_data=valid_generator\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrkevtRSX1Ob","executionInfo":{"status":"ok","timestamp":1697482494977,"user_tz":-330,"elapsed":7239060,"user":{"displayName":"Made Saral","userId":"07554071970660769363"}},"outputId":"918df311-1cd6-4a3e-a7e9-7892c7f75b70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 31721 images belonging to 17 classes.\n","Found 3612 images belonging to 17 classes.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["992/992 [==============================] - 7197s 7s/step - loss: 0.2319 - accuracy: 0.9268 - val_loss: 4.7221 - val_accuracy: 0.3162\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import numpy as np\n","\n","# Load the saved model\n","loaded_model = tf.keras.models.load_model('/content/gdrive/MyDrive/trained_model.h5')  # Replace with the actual path to your saved model\n","\n","# Load and preprocess the image\n","image_path = '/content/gdrive/MyDrive/archive (3)/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Apple_scab/5a178d63-372d-48c4-adb8-d616130ba3f0___FREC_Scab 3104.JPG'\n","image_size = (224, 224)  # Adjust to match the input size of your model\n","\n","img = load_img(image_path, target_size=image_size)\n","img_array = img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n","img_array /= 255.0  # Normalize the image data if needed\n","\n","# Make predictions\n","predictions = loaded_model.predict(img_array)\n","print(predictions)\n","# Assuming your model performs classification and returns class probabilities,\n","# you can extract the predicted class (index with the highest probability) like this:\n","predicted_class_index = np.argmax(predictions)\n","print(predicted_class_index)\n","\n","class_labels = ['Apple___Apple_scab','Apple___Black_rot','Apple___Cedar_apple_rust','Apple___healthy','Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n","'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot','Corn_(maize)___Common_rust_','Corn_(maize)___healthy','Grape___Black_rot',\n","'Grape___Esca_(Black_Measles)','Grape___healthy','Potato___Early_blight','Potato___healthy','Potato___Late_blight','Tomato___Bacterial_spot',\n","'Tomato___healthy','Tomato___Leaf_Mold','Tomato___Tomato_mosaic_virus']\n","predicted_class_label = class_labels[predicted_class_index]\n","\n","\n","print(f\"Predicted class: {predicted_class_label}\")\n","print(f\"Class probabilities: {predictions[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lemzR8pg6Gnq","executionInfo":{"status":"ok","timestamp":1697484739222,"user_tz":-330,"elapsed":5296,"user":{"displayName":"Made Saral","userId":"07554071970660769363"}},"outputId":"24fba407-a2e8-4748-a764-73888ce7544e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","[[3.2719922e-06 2.5704691e-07 2.0384748e-06 6.5522678e-03 1.5759515e-05\n","  6.3415695e-09 4.1954616e-05 1.3876556e-06 8.0515683e-06 7.6236315e-06\n","  1.8280006e-06 6.6624871e-08 1.3526457e-05 2.9282784e-05 1.5951816e-06\n","  8.6411276e-08 9.9332100e-01]]\n","16\n","Predicted class: Tomato___Leaf_Mold\n","Class probabilities: [3.2719922e-06 2.5704691e-07 2.0384748e-06 6.5522678e-03 1.5759515e-05\n"," 6.3415695e-09 4.1954616e-05 1.3876556e-06 8.0515683e-06 7.6236315e-06\n"," 1.8280006e-06 6.6624871e-08 1.3526457e-05 2.9282784e-05 1.5951816e-06\n"," 8.6411276e-08 9.9332100e-01]\n"]}]},{"cell_type":"code","source":["'Apple___Apple_scab','Apple___Black_rot','Apple___Cedar_apple_rust','Apple___healthy','Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n","'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot','Corn_(maize)___Common_rust_','Corn_(maize)___healthy','Grape___Black_rot',\n","'Grape___Esca_(Black_Measles)','Grape___healthy','Potato___Early_blight','Potato___healthy','Potato___Late_blight','Tomato___Bacterial_spot',\n","'Tomato___healthy','Tomato___Leaf_Mold','Tomato___Tomato_mosaic_virus'"],"metadata":{"id":"EcNqQ0py88Bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sx4C_vVpHT6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iLUxebkAHT8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define the paths\n","train_dir = '/content/gdrive/MyDrive/archive (3)/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n","valid_dir = '/content/gdrive/MyDrive/archive (3)/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n","\n","# Define image size and batch size\n","img_size = (224, 224)\n","batch_size = 32\n","\n","# Create data generators with data augmentation for training images\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","valid_generator = valid_datagen.flow_from_directory(\n","    valid_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Load pre-trained ResNet50 model without top (fully connected) layers\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Add custom top layers for your specific classification task\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(17, activation='softmax')  # 17 classes for crop diseases\n","])\n","\n","# Compile the model\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=1e-5)\n","\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=1,\n","    validation_data=valid_generator\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-m5gtNDHT_5","outputId":"a4786874-f87f-4754-d04e-355c1455a9b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 31721 images belonging to 17 classes.\n","Found 3612 images belonging to 17 classes.\n","745/992 [=====================>........] - ETA: 26:54 - loss: 0.2612 - accuracy: 0.9219"]}]}]}